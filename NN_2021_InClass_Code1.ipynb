{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_2021_InClass_Code1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadzaidan99/gitignore/blob/master/NN_2021_InClass_Code1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kas8vur0T7yW"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#input dataset for training\n",
        "\n",
        "X = np.array([[0, 0, 1],\n",
        "              [0, 1, 1],\n",
        "              [1, 0 ,1],\n",
        "              [1, 1, 1]])\n",
        "\n",
        "# output class labels for training\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "# learning rate nu\n",
        "alpha = 0.05\n",
        "batch = 10000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Ri90L0T9DU",
        "outputId": "54665d27-6ecd-4568-e07f-8b8372c59f82"
      },
      "source": [
        "# initialize the weights randomly\n",
        "#  \n",
        "w0 = 2*np.random.random((3,4)) -1 # zero mean and range of -1 to 1 \n",
        "\n",
        "# 1x1 \n",
        "w1 = 2*np.random.random((4,1))\n",
        "\n",
        "w1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4089045 ],\n",
              "       [1.75623487],\n",
              "       [0.05477519],\n",
              "       [1.34093502]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Ua4Pm0fIQz"
      },
      "source": [
        "# eq1\n",
        "def sigmoid(z):\n",
        "  return 1/(1 + np.exp(-z))\n",
        "\n",
        "# eq 2\n",
        "# sigprime = sig * (1-sig(z))\n",
        "def sigmoid_prime(z):\n",
        "  return (z * (1 - z))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N-8n0icf1za",
        "outputId": "76d14d79-d298-41e6-d331-b5ca4bd91132"
      },
      "source": [
        "for cntr in range(batch):\n",
        "\n",
        "  batch_x = X\n",
        "  batch_y = y\n",
        "  n = batch_x.shape[0]# number of training inputs --> 4 \n",
        "  # first input layer : no activation function\n",
        "  a0 = batch_x\n",
        "\n",
        "\n",
        "  # Perform Feedforward operation \n",
        "  z1 = np.dot(a0, w0)\n",
        "  a1 = sigmoid(z1) \n",
        "\n",
        "  # do the calculations for the z values, notice that instead of the sum operator we utilize matrix operation-- dot product\n",
        "\n",
        "  z2 = np.dot(a1, w1)\n",
        "\n",
        "  a2 = sigmoid(z2) # second layer activation aka NN's output values \n",
        "\n",
        "  l2_error = (a2 - batch_y)/n\n",
        "\n",
        "  if cntr % 1000 == 0:\n",
        "    print('Error:' + str(np.mean(np.mean(np.abs(l2_error)))))\n",
        "\n",
        "  # eq 6 in the slide\n",
        "  l2_delta = l2_error * sigmoid_prime(a2)\n",
        "\n",
        "  l1_error = l2_delta.dot(w1.T) \n",
        "\n",
        "  # eq 7 in the slide\n",
        "  l1_delta = l1_error * sigmoid_prime(a1)\n",
        "\n",
        "  # eq 5 in the slide \n",
        "  w1 -= alpha * a1.T.dot(l2_delta)\n",
        "  w0 -= alpha * a0.T.dot(l1_delta)\n",
        "\n",
        "\n",
        "print('Output after training')\n",
        "print (a2)\n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error:0.1250618367898453\n",
            "Error:0.12399999231039671\n",
            "Error:0.12278389640109805\n",
            "Error:0.12061161285194852\n",
            "Error:0.1169127641577947\n",
            "Error:0.11129929005861933\n",
            "Error:0.10412199301457203\n",
            "Error:0.09642593207364891\n",
            "Error:0.08873382732031121\n",
            "Error:0.08026087000870291\n",
            "Output after training\n",
            "[[0.17232579]\n",
            " [0.68120347]\n",
            " [0.77886637]\n",
            " [0.39688452]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}